{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75eef4f3-9d02-48c1-abba-1b51a88b80d3",
   "metadata": {},
   "source": [
    "## 1. How GPU Works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674c8b01-8931-4ef1-ae2c-33de1f01de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. 환경 설정 : 필요한 패키지 설치\n",
    "!pip install pynvml transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff413fc-f2e8-4bba-8724-a3f006de75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 2. 라이브러리 import 및 GPU 확인\n",
    "import torch\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "# GPU 연결 확인\n",
    "if not torch.cuda.is_available():\n",
    "\traise RuntimeError(\"GPU undetected.\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f'Currently using {device}')\n",
    "\n",
    "# NVML 초기화\n",
    "nvmlInit()\n",
    "handle = nvmlDeviceGetHandleByIndex(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a969b191-ad91-478f-b928-7a686d5f7958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[초기 상태] GPU 메모리 사용량: 1.16 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 3. GPU 메모리 사용량 확인 함수 정의 및 초기 상태\n",
    "def print_gpu_mem(label: str):\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    used_gb = info.used / (1024**3)\n",
    "    total_gb = info.total / (1024**3)\n",
    "    print(f'[{label}] GPU 메모리 사용량: {used_gb:.2f} GB / {total_gb:.2f} GB')\n",
    "\n",
    "print_gpu_mem(\"초기 상태\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77d500a-6e6c-4d7f-accd-6c6d7d4dcb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CPU 텐서 생성 후] GPU 메모리 사용량: 1.16 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 4. CPU 텐서 생성 (GPU 사용 전)\n",
    "# 512*512 크기 텐서를 CPU 상에서 생성해보자.\n",
    "x_cpu = torch.randn(512, 512)\n",
    "# GPU 메모리 사용량 변화 없음\n",
    "print_gpu_mem(\"CPU 텐서 생성 후\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474ca6c7-0241-49bf-86be-1e05ddd54d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1x1 텐서 GPU 로드 후] GPU 메모리 사용량: 1.38 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 5. 작은 GPU 텐서 (1*1) 올리기\n",
    "# 1x1 크기 텐서를 GPU로 옮기면 CUDA 커널이 로드되어 약 1-2GB 사용\n",
    "x_small = torch.randn(1, 1).to(device)\n",
    "print_gpu_mem(\"1x1 텐서 GPU 로드 후\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9cbb021-bd18-45f7-9c0c-2762dcdfe00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "실제 텐서 데이터 크기: 4 B  (0.000004 MB, 0.000000004 GB)\n"
     ]
    }
   ],
   "source": [
    "# 5.1. 실제 텐서 데이터 크기 확인\n",
    "import torch\n",
    "\n",
    "# 1x1 float32 텐서 생성 및 GPU로 이동\n",
    "x = torch.randn(1, 1, device=\"cuda:0\")\n",
    "\n",
    "# 요소 개수 및 원소당 바이트 수 계산\n",
    "numel = x.nelement()         # 요소 개수 : 1\n",
    "bytes_per = x.element_size() # float32 한 요소당 4바이트\n",
    "\n",
    "# 실제 데이터 바이트 수 계산\n",
    "tensor_bytes = numel * bytes_per # 총 4byte\n",
    "tensor_mb = tensor_bytes / (1024 ** 2)\n",
    "tensor_gb = tensor_bytes / (1024 ** 3)\n",
    "\n",
    "# 출력: B, MB, GB 단위 모두 표시\n",
    "print(f\"실제 텐서 데이터 크기: {tensor_bytes} B  ({tensor_mb:.6f} MB, {tensor_gb:.9f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd17160-3b04-4d6c-bc4d-ecf877c0837b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 12:59:22.214347: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-01 12:59:22.221740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754020762.230221   11067 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754020762.232925   11067 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754020762.239910   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754020762.239917   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754020762.239917   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754020762.239918   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-01 12:59:22.242128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the model checkpoint at google-bert/bert-large-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT-Large GPU 로드 후] GPU 메모리 사용량: 2.63 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 6. BERT-Large 모델 로드 및 GPU로 이동\n",
    "from transformers import BertForMaskedLM, BertTokenizerFast\n",
    "\n",
    "# 모델과 토크나이저 로드\n",
    "model_name = \"google-bert/bert-large-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# 모델을 GPU로 이동\n",
    "model.to(device)\n",
    "print_gpu_mem(\"BERT-Large GPU 로드 후\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f10e16f-4c3f-41bc-9a00-ff5729feeefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 13.2833\n",
      "[학습 스텝(batch=4) 후] GPU 메모리 사용량: 7.77 GB / 15.92 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sallysooo/miniforge3/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 7. 간단 학습 스텝 (batch size=4)\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# 더미 입력(batch_size=4, seq_len=8) 생성\n",
    "batch_size, seq_len = 4, 8\n",
    "input_ids = torch.randint(0, tokenizer.vocab_size, (batch_size, seq_len), device=device)\n",
    "attention_mask = torch.ones_like(input_ids, device=device)\n",
    "labels = input_ids.clone() # 자기 자신을 예측하도록\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f'Loss: {loss.item():.4f}')\n",
    "print_gpu_mem(\"학습 스텝(batch=4) 후\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889232b4-8d0e-46d6-afb6-3c8bae4eb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def time_operation(operation, *args, n_iters=100):\n",
    "    # GPU sync 후 정확한 시간 측정 시작\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        operation(*args)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_time_ms = (end - start) / n_iters * 1000  # ms 단위\n",
    "    return avg_time_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ffdfcf7-836c-42c5-bb9b-6a7dec92032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Operation  Avg Time (ms)\n",
      "0               GEMM (2048*2048)       0.590971\n",
      "1          LayerNorm (2048*2048)       0.019050\n",
      "2  Element-wise ReLU (2048*2048)       0.013139\n"
     ]
    }
   ],
   "source": [
    "# 1) GEMM (2048*2048)\n",
    "size = 2048\n",
    "A = torch.randn(size, size, device=device)\n",
    "B = torch.randn(size, size, device=device)\n",
    "gemm_time = time_operation(lambda x, y: x.matmul(y), A, B)\n",
    "\n",
    "# 2) LayerNorm (2048*2048)\n",
    "seq_len, hidden = 2048, 2048\n",
    "x = torch.randn(seq_len, hidden, device=device)\n",
    "ln = torch.nn.LayerNorm(hidden).to(device)\n",
    "ln_time = time_operation(lambda inp: ln(inp), x)\n",
    "\n",
    "# 3) Element-wise ReLU (2048*2048)\n",
    "y = torch.randn(size, size, device=device)\n",
    "elt_time = time_operation(lambda inp: inp.relu(), y)\n",
    "\n",
    "# 결과 프레임\n",
    "df = pd.DataFrame({\n",
    "\t'Operation': ['GEMM (2048*2048)', 'LayerNorm (2048*2048)', 'Element-wise ReLU (2048*2048)'],\n",
    "    'Avg Time (ms)': [gemm_time, ln_time, elt_time]\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34263eac-4377-40e4-a823-7fb6798ab93f",
   "metadata": {},
   "source": [
    "## 2. Batch Size Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6016b089-3557-4ea0-b987-ae861b1c6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B=   4 | Time:   2.01 ms | ∆Mem: +0.03 GB\n",
      "B=   8 | Time:   1.50 ms | ∆Mem: +0.06 GB\n",
      "B=  16 | Time:   1.46 ms | ∆Mem: +0.06 GB\n",
      "B=  32 | Time:   1.42 ms | ∆Mem: +0.06 GB\n",
      "B=  64 | Time:   1.56 ms | ∆Mem: +0.06 GB\n",
      "B= 128 | Time:   1.55 ms | ∆Mem: +0.06 GB\n",
      "B= 256 | Time:   1.49 ms | ∆Mem: +0.06 GB\n",
      "B= 512 | Time:   1.57 ms | ∆Mem: +0.06 GB\n",
      "B=1024 | Time:   1.83 ms | ∆Mem: +0.06 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11067/1360385232.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_11067/1360385232.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n"
     ]
    }
   ],
   "source": [
    "# 본인 컴퓨터 사양에서는 얼마의 배치가 최적인지? (사용 모델 및 연산 종류 등에 따라서 더 달라질 수 있음)\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2048, 2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048, 2048)\n",
    ").to(device)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for B in [4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "    x = torch.randn(B, 2048, device=device)\n",
    "    y = torch.randn(B, 2048, device=device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    mem_start = torch.cuda.memory_allocated()\n",
    "\n",
    "    start = time.time()\n",
    "    with autocast(dtype=torch.float16):\n",
    "        out = model(x)\n",
    "        loss = (out - y).abs().mean()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_ms = (time.time() - start) * 1000\n",
    "\n",
    "    mem_end = torch.cuda.memory_allocated()\n",
    "    delta_gb = (mem_end - mem_start) / 1024**3\n",
    "\n",
    "    print(f\"B={B:4} | Time: {elapsed_ms:6.2f} ms | ∆Mem: {delta_gb:+.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b1f06a5-6dc5-4c70-b37c-18cb77dffcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 dtype = torch.float32\n",
      "▶ 511×511 행렬곱: 0.03 ms\n",
      "▶ 512×512 행렬곱: 0.02 ms\n",
      "▶ 513×513 행렬곱: 0.04 ms\n",
      "\n",
      "🔍 dtype = torch.float16\n",
      "▶ 511×511 행렬곱: 0.02 ms\n",
      "▶ 512×512 행렬곱: 0.01 ms\n",
      "▶ 513×513 행렬곱: 0.02 ms\n"
     ]
    }
   ],
   "source": [
    "# Tiling experiment\n",
    "# 테스트할 데이터 타입들\n",
    "dtypes = [torch.float32, torch.float16]\n",
    "\n",
    "# 테스트할 행렬 크기들\n",
    "shapes = [\n",
    "    (511, 511),  # 타일보다 약간 작은 경우\n",
    "    (512, 512),  # 이상적인 타일 크기\n",
    "    (513, 513),  # 타일보다 약간 큰 경우\n",
    "]\n",
    "\n",
    "for dtype in dtypes:\n",
    "    print(f\"\\n🔍 dtype = {dtype}\")\n",
    "    for H, W in shapes:\n",
    "        A = torch.randn(H, W, device=device, dtype=dtype)\n",
    "        B = torch.randn(W, H, device=device, dtype=dtype)\n",
    "\n",
    "        # 워밍업 (초기 CUDA 실행 지연 제거용)\n",
    "        for _ in range(5):\n",
    "            _ = A @ B\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # 속도 측정\n",
    "        start = time.time()\n",
    "        for _ in range(20):\n",
    "            _ = A @ B\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed = (time.time() - start) / 20\n",
    "\n",
    "        print(f\"▶ {H}×{W} 행렬곱: {elapsed * 1000:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9a78b-8e42-4730-924c-e9cc87bde4dc",
   "metadata": {},
   "source": [
    "## 3. Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d7f58a-476a-4b80-990a-2b597885a0c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 9.91M/9.91M [00:03<00:00, 2.69MB/s]\n",
      "100%|███████████████████████████████████████| 28.9k/28.9k [00:00<00:00, 144kB/s]\n",
      "100%|██████████████████████████████████████| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
      "100%|██████████████████████████████████████| 4.54k/4.54k [00:00<00:00, 6.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1], Step 40, Loss: 23.0305\n",
      "[Epoch 1], Step 80, Loss: 22.8590\n",
      "[Epoch 1], Step 120, Loss: 22.6783\n",
      "[Epoch 1], Step 160, Loss: 22.5134\n",
      "[Epoch 1], Step 200, Loss: 22.3058\n",
      "[Epoch 1], Step 240, Loss: 22.1221\n",
      "[Epoch 1], Step 280, Loss: 21.9336\n",
      "[Epoch 1], Step 320, Loss: 21.6852\n",
      "[Epoch 1], Step 360, Loss: 21.5077\n",
      "[Epoch 1], Step 400, Loss: 21.3264\n",
      "[Epoch 1], Step 440, Loss: 21.0508\n",
      "[Epoch 1], Step 480, Loss: 20.8227\n",
      "[Epoch 1], Step 520, Loss: 20.6629\n",
      "[Epoch 1], Step 560, Loss: 20.3314\n",
      "[Epoch 1], Step 600, Loss: 20.0644\n",
      "[Epoch 1], Step 640, Loss: 19.7670\n",
      "[Epoch 1], Step 680, Loss: 19.6221\n",
      "[Epoch 1], Step 720, Loss: 19.3917\n",
      "[Epoch 1], Step 760, Loss: 19.0303\n",
      "[Epoch 1], Step 800, Loss: 18.8091\n",
      "[Epoch 1], Step 840, Loss: 18.3280\n",
      "[Epoch 1], Step 880, Loss: 17.9145\n",
      "[Epoch 1], Step 920, Loss: 17.6815\n",
      "[Epoch 1], Step 960, Loss: 17.3458\n",
      "[Epoch 1], Step 1000, Loss: 16.9637\n",
      "[Epoch 1], Step 1040, Loss: 16.5880\n",
      "[Epoch 1], Step 1080, Loss: 16.3032\n",
      "[Epoch 1], Step 1120, Loss: 15.8250\n",
      "[Epoch 1], Step 1160, Loss: 15.5598\n",
      "[Epoch 1], Step 1200, Loss: 15.0634\n",
      "[Epoch 1], Step 1240, Loss: 14.9601\n",
      "[Epoch 1], Step 1280, Loss: 14.7189\n",
      "[Epoch 1], Step 1320, Loss: 14.3601\n",
      "[Epoch 1], Step 1360, Loss: 14.0337\n",
      "[Epoch 1], Step 1400, Loss: 13.4467\n",
      "[Epoch 1], Step 1440, Loss: 13.1825\n",
      "[Epoch 1], Step 1480, Loss: 13.2653\n",
      "[Epoch 1], Step 1520, Loss: 12.6712\n",
      "[Epoch 1], Step 1560, Loss: 12.2089\n",
      "[Epoch 1], Step 1600, Loss: 12.2819\n",
      "[Epoch 1], Step 1640, Loss: 12.2713\n",
      "[Epoch 1], Step 1680, Loss: 11.6150\n",
      "[Epoch 1], Step 1720, Loss: 11.3809\n",
      "[Epoch 1], Step 1760, Loss: 11.0676\n",
      "[Epoch 1], Step 1800, Loss: 11.2058\n",
      "[Epoch 1], Step 1840, Loss: 10.9255\n",
      "[Epoch 2], Step 40, Loss: 10.6119\n",
      "[Epoch 2], Step 80, Loss: 10.1341\n",
      "[Epoch 2], Step 120, Loss: 9.9602\n",
      "[Epoch 2], Step 160, Loss: 9.8754\n",
      "[Epoch 2], Step 200, Loss: 9.8871\n",
      "[Epoch 2], Step 240, Loss: 9.5684\n",
      "[Epoch 2], Step 280, Loss: 9.3752\n",
      "[Epoch 2], Step 320, Loss: 9.2316\n",
      "[Epoch 2], Step 360, Loss: 8.7818\n",
      "[Epoch 2], Step 400, Loss: 8.8345\n",
      "[Epoch 2], Step 440, Loss: 8.7836\n",
      "[Epoch 2], Step 480, Loss: 8.7836\n",
      "[Epoch 2], Step 520, Loss: 8.4388\n",
      "[Epoch 2], Step 560, Loss: 8.3114\n",
      "[Epoch 2], Step 600, Loss: 8.2199\n",
      "[Epoch 2], Step 640, Loss: 8.4316\n",
      "[Epoch 2], Step 680, Loss: 8.1363\n",
      "[Epoch 2], Step 720, Loss: 8.1010\n",
      "[Epoch 2], Step 760, Loss: 7.7610\n",
      "[Epoch 2], Step 800, Loss: 7.9665\n",
      "[Epoch 2], Step 840, Loss: 7.8165\n",
      "[Epoch 2], Step 880, Loss: 7.4888\n",
      "[Epoch 2], Step 920, Loss: 7.3141\n",
      "[Epoch 2], Step 960, Loss: 7.4696\n",
      "[Epoch 2], Step 1000, Loss: 7.3647\n",
      "[Epoch 2], Step 1040, Loss: 7.2859\n",
      "[Epoch 2], Step 1080, Loss: 7.1032\n",
      "[Epoch 2], Step 1120, Loss: 7.2152\n",
      "[Epoch 2], Step 1160, Loss: 7.3305\n",
      "[Epoch 2], Step 1200, Loss: 7.0387\n",
      "[Epoch 2], Step 1240, Loss: 6.7609\n",
      "[Epoch 2], Step 1280, Loss: 6.8497\n",
      "[Epoch 2], Step 1320, Loss: 6.5773\n",
      "[Epoch 2], Step 1360, Loss: 6.9756\n",
      "[Epoch 2], Step 1400, Loss: 6.4442\n",
      "[Epoch 2], Step 1440, Loss: 6.3468\n",
      "[Epoch 2], Step 1480, Loss: 6.1935\n",
      "[Epoch 2], Step 1520, Loss: 6.0806\n",
      "[Epoch 2], Step 1560, Loss: 6.5773\n",
      "[Epoch 2], Step 1600, Loss: 6.3034\n",
      "[Epoch 2], Step 1640, Loss: 6.2931\n",
      "[Epoch 2], Step 1680, Loss: 6.3009\n",
      "[Epoch 2], Step 1720, Loss: 6.4374\n",
      "[Epoch 2], Step 1760, Loss: 6.3416\n",
      "[Epoch 2], Step 1800, Loss: 6.2634\n",
      "[Epoch 2], Step 1840, Loss: 6.0168\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. 하이퍼파라미터 설정\n",
    "batch_size = 32              # 작은 배치\n",
    "accumulation_steps = 4       # 누적할 step 수\n",
    "lr = 0.01\n",
    "num_epochs = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. 데이터셋 준비\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 3. 모델 정의\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "# 4. 손실 함수 및 옵티마이저\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# 5. 학습 루프 (Gradient Accumulation)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # forward + loss\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss = loss / accumulation_steps  # 누적을 위한 평균화\n",
    "\n",
    "        # backward (누적)\n",
    "        loss.backward()\n",
    "\n",
    "        # 일정 횟수마다 optimizer step + grad 초기화\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i + 1) % (accumulation_steps * 10) == 0:\n",
    "            print(f\"[Epoch {epoch+1}], Step {i+1}, Loss: {running_loss:.4f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a04918-3b89-4a0e-8cb7-c3674d705cda",
   "metadata": {},
   "source": [
    "## 4. Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d15989-7861-4135-8b86-4277b0a9abd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7616e-02, -3.1428e-02,  6.8262e-03,  3.8644e-02, -6.3441e-03,\n",
      "         -1.9613e-02,  4.1357e-02,  1.9341e-02,  5.2598e-03,  6.3985e-03],\n",
      "        [-1.6576e-02, -5.3709e-02,  4.7012e-03,  4.2796e-02,  3.5075e-02,\n",
      "         -2.6529e-02,  2.8517e-02,  1.2006e-02, -3.5837e-05, -4.5435e-03],\n",
      "        [ 9.6738e-04, -1.7537e-02, -1.0928e-02,  3.5094e-02, -4.9903e-03,\n",
      "         -8.8588e-03,  2.0412e-02,  9.8992e-03,  1.5639e-02, -2.4861e-03],\n",
      "        [-2.0573e-02, -3.0641e-02, -1.2131e-02,  4.4564e-02,  1.8414e-02,\n",
      "         -1.8255e-02,  3.4164e-02,  1.8577e-03,  3.5629e-03,  5.7991e-03],\n",
      "        [-1.6200e-02, -5.1690e-02,  1.1797e-02,  5.1125e-02,  1.7877e-02,\n",
      "         -1.3097e-02,  1.8381e-02,  2.4275e-02,  1.6612e-03, -4.7723e-03],\n",
      "        [-5.3039e-04, -2.5847e-02,  2.3918e-02,  3.3754e-02,  5.1899e-03,\n",
      "         -9.6100e-03,  3.9026e-02,  1.4256e-02,  5.0952e-04, -3.9692e-03],\n",
      "        [-1.2131e-02, -1.7107e-02,  4.9355e-03,  5.8596e-02,  1.5842e-02,\n",
      "         -2.2700e-02,  1.5244e-02,  5.9020e-03, -3.7590e-03,  1.6441e-02],\n",
      "        [-2.3179e-03, -4.4885e-02,  2.6362e-02,  3.5705e-02, -1.7704e-03,\n",
      "         -1.3421e-02,  2.5807e-02, -5.8480e-03, -1.3311e-02, -1.0898e-02],\n",
      "        [-1.0639e-02, -3.5169e-02,  6.8398e-04,  4.1331e-02,  1.6262e-02,\n",
      "         -2.9964e-03,  5.2490e-03,  9.6564e-03, -1.3941e-02, -5.1538e-03],\n",
      "        [-3.8005e-03, -3.9539e-02,  1.1223e-02,  2.6906e-02,  1.2140e-02,\n",
      "         -2.7797e-02,  2.3331e-02,  5.4023e-04, -3.1519e-04,  9.0969e-03],\n",
      "        [-1.2232e-02, -4.3731e-02,  4.4464e-03,  5.5763e-02, -9.3744e-03,\n",
      "         -1.0475e-02,  2.2034e-02,  1.4444e-02, -3.6468e-03, -5.0451e-03],\n",
      "        [ 1.1104e-02, -3.7780e-02,  2.3388e-02,  4.8496e-02,  9.3407e-03,\n",
      "         -2.1039e-02,  2.6993e-02,  1.0775e-03,  5.6857e-03, -6.7896e-03],\n",
      "        [-9.6015e-03, -2.7423e-02,  5.3220e-03,  3.9902e-02,  3.6802e-03,\n",
      "         -1.0856e-02,  2.8703e-02, -8.3622e-04, -7.6974e-03,  5.7542e-04],\n",
      "        [-1.8175e-02, -4.3599e-02,  7.9308e-04,  3.4553e-02,  3.6372e-03,\n",
      "         -3.1136e-02,  3.8265e-02,  2.1064e-02, -1.0095e-02, -6.9517e-03],\n",
      "        [-4.9030e-03, -3.0467e-02,  1.2696e-02,  3.2622e-02,  4.4317e-03,\n",
      "         -1.1520e-02,  2.5786e-02,  1.5583e-03, -8.8683e-03,  3.6830e-03],\n",
      "        [-1.6943e-02, -3.1245e-02,  1.6653e-02,  4.9827e-02,  9.2806e-03,\n",
      "         -1.8329e-02,  2.7521e-02,  1.7156e-02,  7.3846e-03, -1.1943e-02],\n",
      "        [-2.0710e-02, -3.0071e-02,  1.2386e-02,  4.2777e-02,  7.1175e-03,\n",
      "         -2.2052e-02,  8.5191e-03,  1.0244e-02, -3.6861e-03, -8.8057e-03],\n",
      "        [-1.7331e-02, -2.9393e-02, -2.8608e-03,  3.8696e-02,  5.9139e-03,\n",
      "         -2.7232e-02,  1.6828e-02, -4.6842e-03, -1.5204e-02, -1.0062e-02],\n",
      "        [-9.0373e-03, -3.6815e-02,  4.7825e-04,  4.9496e-02,  9.4228e-03,\n",
      "         -2.5500e-02,  2.0563e-02,  2.4567e-02,  7.8603e-03, -1.1906e-02],\n",
      "        [-2.7435e-02, -3.1737e-02,  1.2086e-02,  3.2206e-02,  1.1814e-02,\n",
      "         -3.3808e-02,  9.8887e-03, -8.2141e-03,  2.6903e-03, -1.8056e-02],\n",
      "        [-1.9838e-02, -4.4139e-02, -6.0359e-03,  3.4208e-02, -2.7787e-03,\n",
      "         -1.3976e-02,  3.2824e-02,  5.3565e-03, -6.4125e-03, -1.7383e-02],\n",
      "        [-2.6893e-02, -2.9860e-02, -1.0450e-02,  3.6142e-02, -4.2210e-03,\n",
      "          4.2004e-04,  2.1117e-02, -5.6983e-04, -2.2531e-03,  8.5638e-03],\n",
      "        [-3.1545e-04, -5.7487e-02, -5.6249e-03,  2.3715e-02, -1.0125e-02,\n",
      "         -2.4930e-02,  2.2078e-02,  2.5796e-02, -1.3907e-02, -3.2542e-02],\n",
      "        [-6.5236e-03, -4.0517e-02, -1.6547e-02,  3.8311e-02, -1.2152e-03,\n",
      "         -7.4797e-03,  1.7754e-02,  9.6697e-03, -3.3358e-03,  5.2242e-03],\n",
      "        [-1.7550e-02, -4.1027e-02,  1.2290e-02,  2.6614e-02,  1.4921e-02,\n",
      "         -2.8765e-03,  1.7479e-02,  9.4391e-03,  1.0654e-03, -1.6430e-02],\n",
      "        [-6.4433e-03, -2.9347e-02,  5.0285e-03,  3.4487e-02,  1.4234e-02,\n",
      "         -2.7236e-02,  2.6529e-02, -1.0366e-02, -7.8999e-03,  3.2923e-03],\n",
      "        [-3.4124e-03, -4.3861e-02, -3.1501e-03,  3.5361e-02, -5.6704e-03,\n",
      "         -9.6782e-03,  3.0645e-02,  1.4632e-02,  2.4508e-02, -1.8150e-02],\n",
      "        [-2.5119e-02, -5.0505e-02,  8.7255e-03,  4.5884e-02,  1.0169e-02,\n",
      "         -2.9987e-02,  2.9567e-02, -1.1078e-02, -2.3118e-02, -1.3127e-02],\n",
      "        [-5.6929e-03, -4.3776e-02, -6.8075e-03,  4.1075e-02,  1.2047e-02,\n",
      "         -2.5639e-02,  2.7109e-02,  2.2094e-02, -7.9536e-03,  1.7324e-02],\n",
      "        [-1.7905e-02, -4.0238e-02,  9.0708e-03,  4.6888e-02, -5.2126e-03,\n",
      "         -8.8711e-03,  3.5040e-02,  8.1595e-03,  5.1214e-04, -9.8214e-03],\n",
      "        [-3.3020e-02, -3.4794e-02,  1.1738e-02,  4.5333e-02,  1.4586e-02,\n",
      "         -9.6913e-03,  1.2140e-02,  8.4179e-03, -1.2599e-03, -1.4961e-02],\n",
      "        [-1.2854e-02, -3.8555e-02, -9.0583e-03,  4.3058e-02, -1.0390e-02,\n",
      "         -1.6606e-02,  1.9577e-02,  8.0136e-04,  2.3446e-03,  4.5492e-03],\n",
      "        [ 3.7452e-03, -3.2292e-02,  1.7012e-02,  5.0920e-02,  2.0737e-02,\n",
      "         -2.6386e-02,  3.0444e-02,  2.0558e-02, -8.9942e-03, -8.5440e-03],\n",
      "        [-8.1378e-04, -3.5795e-02,  5.2273e-04,  4.0807e-02,  3.5640e-03,\n",
      "         -1.7721e-02,  3.8172e-02,  1.2146e-02, -5.9907e-03,  4.3804e-03],\n",
      "        [-1.1172e-02, -5.0470e-02,  1.2142e-02,  3.0292e-02,  7.7941e-03,\n",
      "         -1.5085e-02,  2.5021e-02,  2.4344e-03, -5.0067e-03,  6.6600e-04],\n",
      "        [-1.5735e-02, -4.2036e-02, -7.3203e-03,  3.4951e-02, -1.2344e-02,\n",
      "         -2.4653e-02,  3.6478e-02,  9.5518e-03, -1.4927e-02, -7.7627e-03],\n",
      "        [-2.5061e-03, -2.6327e-02,  5.1696e-03,  4.3396e-02,  1.2796e-03,\n",
      "          6.3088e-04,  1.0009e-02,  1.4256e-02,  2.5333e-02, -1.1108e-02],\n",
      "        [-1.6033e-02, -2.9202e-02,  8.4761e-03,  3.2263e-02,  3.1849e-03,\n",
      "         -1.1917e-02,  2.3907e-02,  1.0794e-02, -8.9477e-03, -4.2427e-03],\n",
      "        [ 8.4052e-03, -5.6778e-02,  6.7151e-03,  3.3987e-02,  9.9752e-03,\n",
      "         -1.7247e-02,  2.7354e-02,  2.3763e-03,  7.7211e-03, -2.1166e-02],\n",
      "        [-1.3377e-02, -3.4603e-02,  3.3627e-03,  1.9016e-02, -3.6885e-04,\n",
      "         -1.1118e-02,  3.6261e-02,  1.7723e-02, -7.3170e-03, -9.9798e-04],\n",
      "        [-2.4353e-02, -3.1709e-02, -1.3765e-03,  2.9903e-02,  1.0268e-02,\n",
      "         -2.9177e-02,  2.4618e-02, -5.6468e-05, -2.3101e-02, -5.7912e-03],\n",
      "        [-2.0952e-02, -2.7326e-02,  1.5117e-02,  4.3141e-02,  1.0216e-02,\n",
      "         -1.9674e-02,  1.8570e-02, -5.2182e-03,  6.5174e-03, -4.7797e-03],\n",
      "        [-1.2090e-02, -4.4012e-02,  2.6967e-03,  4.4411e-02,  1.0862e-02,\n",
      "         -2.3770e-02,  2.0148e-02,  1.1667e-02, -5.2732e-03, -6.8767e-03],\n",
      "        [-2.3894e-02, -3.8068e-02,  1.0254e-02,  5.4305e-02, -1.1804e-02,\n",
      "         -1.4340e-02,  3.3792e-02,  8.7996e-03, -6.8141e-03, -7.6301e-03],\n",
      "        [-1.0248e-02, -3.9113e-02,  1.6810e-02,  3.9211e-02,  1.0068e-02,\n",
      "         -5.8659e-03,  1.4435e-02, -7.9668e-03,  1.3434e-02, -6.0932e-03],\n",
      "        [-1.9557e-02, -2.7805e-02,  4.6363e-04,  4.6775e-02,  8.6132e-03,\n",
      "         -1.3958e-02,  2.1014e-02,  6.9003e-03, -1.4121e-02,  9.0437e-04],\n",
      "        [-1.5235e-02, -6.8470e-03,  1.5901e-03,  4.6534e-02, -2.8514e-03,\n",
      "         -1.5324e-03,  2.5945e-02,  8.1543e-03, -9.8737e-03, -5.2560e-03],\n",
      "        [-1.4691e-02, -3.5444e-02,  2.9589e-04,  3.2138e-02,  5.3693e-03,\n",
      "         -2.5067e-02,  1.1407e-02,  1.6632e-02,  7.7760e-03, -6.1849e-03],\n",
      "        [-1.1573e-02, -3.7984e-02, -1.7798e-04,  4.0442e-02,  1.1733e-02,\n",
      "         -1.3463e-02,  1.4173e-02,  2.6836e-03, -1.0517e-02,  4.5877e-03],\n",
      "        [-1.6141e-02, -2.9408e-02,  1.0866e-02,  4.8236e-02,  1.0781e-02,\n",
      "         -1.1109e-02,  1.8712e-02,  1.4089e-02, -3.1054e-03,  3.8409e-03],\n",
      "        [-6.8208e-03, -3.9689e-02,  1.2541e-02,  4.4410e-02,  6.2501e-05,\n",
      "         -9.6774e-03,  3.7307e-02, -4.1606e-03, -1.9793e-03,  2.8538e-03],\n",
      "        [-1.5495e-02, -4.0938e-02,  5.9723e-03,  3.8965e-02,  1.7904e-03,\n",
      "         -2.3624e-02,  1.9916e-02,  4.6189e-03, -9.1278e-03,  9.6748e-03],\n",
      "        [-1.0471e-02, -5.3505e-02, -3.0170e-03,  5.9645e-02,  1.4322e-03,\n",
      "         -1.5734e-02,  1.3923e-02,  2.0365e-02, -1.3117e-02, -1.1064e-02],\n",
      "        [-1.2454e-02, -3.7375e-02, -1.1405e-02,  3.7063e-02,  3.8939e-03,\n",
      "         -1.8590e-02,  1.3661e-02,  8.6877e-03,  8.2183e-03,  2.6843e-03],\n",
      "        [-1.2463e-02, -3.2962e-02,  5.1597e-03,  5.5823e-02, -3.8621e-03,\n",
      "         -6.5245e-03,  2.3848e-02,  3.5166e-02, -1.6691e-02, -2.4696e-04],\n",
      "        [-8.7495e-03, -4.3456e-02, -2.5123e-04,  4.2580e-02,  1.4911e-03,\n",
      "         -2.6320e-02,  4.2281e-02,  2.6967e-03,  2.2592e-03,  1.4167e-03],\n",
      "        [ 4.0432e-03, -2.8470e-02, -4.3356e-03,  2.3731e-02,  2.8476e-03,\n",
      "         -2.8702e-03,  1.0899e-02,  1.4147e-02, -1.6634e-02,  1.1416e-02],\n",
      "        [ 1.8978e-03, -3.1771e-02,  3.6943e-03,  4.2221e-02,  1.9016e-03,\n",
      "         -1.0534e-02,  3.7689e-02,  1.8592e-02, -1.9038e-03,  3.1514e-03],\n",
      "        [-1.9197e-02, -3.3564e-02,  1.7656e-02,  5.5362e-02,  2.5311e-02,\n",
      "         -2.4033e-02,  3.1531e-02, -3.1395e-04, -1.8839e-03,  4.4549e-03],\n",
      "        [-3.2466e-02, -3.1456e-02,  6.4839e-03,  3.1773e-02,  5.9690e-03,\n",
      "         -1.1682e-02,  1.9059e-02,  2.3183e-02, -1.2865e-02, -7.0795e-03],\n",
      "        [-2.4759e-02, -4.0718e-02,  2.7331e-03,  4.0274e-02,  1.0598e-02,\n",
      "         -1.9789e-02,  2.4178e-02,  1.9009e-02, -2.3519e-02, -1.1667e-02],\n",
      "        [-1.5732e-02, -3.7768e-02,  2.2015e-03,  4.6788e-02, -8.9801e-03,\n",
      "         -7.1381e-03,  2.0617e-02,  1.1092e-02, -2.8157e-02, -1.2468e-02],\n",
      "        [-8.4339e-03, -3.0727e-02,  4.6438e-03,  3.1174e-02,  6.3490e-03,\n",
      "         -2.4129e-02,  3.2648e-02,  9.0020e-03, -5.6178e-03,  8.6927e-03],\n",
      "        [-2.5939e-02, -1.8101e-02,  3.7063e-03,  4.3243e-02,  2.2336e-02,\n",
      "         -1.5387e-02,  1.5589e-02,  1.9052e-02, -1.7311e-02,  3.8516e-03]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "class MyBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return checkpoint.checkpoint(self.seq, x)\n",
    "\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = MyBlock()\n",
    "        self.block2 = MyBlock()\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = BigModel().cuda()\n",
    "x = torch.randn(64, 1024, device='cuda')  # batch size = 64\n",
    "output = model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c5866-1adb-475f-a098-98bae04aa373",
   "metadata": {},
   "source": [
    "## 5. Mixed Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b88c3-9643-4327-8ad3-4aec2250c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,                # 실 배치\n",
    "    gradient_accumulation_steps=8,                # 누적 배치 → 총 4x8=32\n",
    "    fp16=True,                                    # Mixed Precision 활성화 (FP16)\n",
    "    # bf16=True,                                  # BF16 사용 시 주석 해제\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    report_to=\"wandb\",                            # WandB 로깅\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

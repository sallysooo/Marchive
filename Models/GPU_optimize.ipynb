{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "75eef4f3-9d02-48c1-abba-1b51a88b80d3",
   "metadata": {},
   "source": [
    "## 1. How GPU Works?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "674c8b01-8931-4ef1-ae2c-33de1f01de0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. í™˜ê²½ ì„¤ì • : í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
    "!pip install pynvml transformers --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cff413fc-f2e8-4bba-8724-a3f006de75f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently using cuda:0\n"
     ]
    }
   ],
   "source": [
    "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ import ë° GPU í™•ì¸\n",
    "import torch\n",
    "from pynvml import nvmlInit, nvmlDeviceGetHandleByIndex, nvmlDeviceGetMemoryInfo\n",
    "\n",
    "# GPU ì—°ê²° í™•ì¸\n",
    "if not torch.cuda.is_available():\n",
    "\traise RuntimeError(\"GPU undetected.\")\n",
    "device = torch.device(\"cuda:0\")\n",
    "print(f'Currently using {device}')\n",
    "\n",
    "# NVML ì´ˆê¸°í™”\n",
    "nvmlInit()\n",
    "handle = nvmlDeviceGetHandleByIndex(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a969b191-ad91-478f-b928-7a686d5f7958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ì´ˆê¸° ìƒíƒœ] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 1.16 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 3. GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸ í•¨ìˆ˜ ì •ì˜ ë° ì´ˆê¸° ìƒíƒœ\n",
    "def print_gpu_mem(label: str):\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    used_gb = info.used / (1024**3)\n",
    "    total_gb = info.total / (1024**3)\n",
    "    print(f'[{label}] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {used_gb:.2f} GB / {total_gb:.2f} GB')\n",
    "\n",
    "print_gpu_mem(\"ì´ˆê¸° ìƒíƒœ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e77d500a-6e6c-4d7f-accd-6c6d7d4dcb2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CPU í…ì„œ ìƒì„± í›„] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 1.16 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 4. CPU í…ì„œ ìƒì„± (GPU ì‚¬ìš© ì „)\n",
    "# 512*512 í¬ê¸° í…ì„œë¥¼ CPU ìƒì—ì„œ ìƒì„±í•´ë³´ì.\n",
    "x_cpu = torch.randn(512, 512)\n",
    "# GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ë³€í™” ì—†ìŒ\n",
    "print_gpu_mem(\"CPU í…ì„œ ìƒì„± í›„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "474ca6c7-0241-49bf-86be-1e05ddd54d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1x1 í…ì„œ GPU ë¡œë“œ í›„] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 1.38 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 5. ì‘ì€ GPU í…ì„œ (1*1) ì˜¬ë¦¬ê¸°\n",
    "# 1x1 í¬ê¸° í…ì„œë¥¼ GPUë¡œ ì˜®ê¸°ë©´ CUDA ì»¤ë„ì´ ë¡œë“œë˜ì–´ ì•½ 1-2GB ì‚¬ìš©\n",
    "x_small = torch.randn(1, 1).to(device)\n",
    "print_gpu_mem(\"1x1 í…ì„œ GPU ë¡œë“œ í›„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9cbb021-bd18-45f7-9c0c-2762dcdfe00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì‹¤ì œ í…ì„œ ë°ì´í„° í¬ê¸°: 4 B  (0.000004 MB, 0.000000004 GB)\n"
     ]
    }
   ],
   "source": [
    "# 5.1. ì‹¤ì œ í…ì„œ ë°ì´í„° í¬ê¸° í™•ì¸\n",
    "import torch\n",
    "\n",
    "# 1x1 float32 í…ì„œ ìƒì„± ë° GPUë¡œ ì´ë™\n",
    "x = torch.randn(1, 1, device=\"cuda:0\")\n",
    "\n",
    "# ìš”ì†Œ ê°œìˆ˜ ë° ì›ì†Œë‹¹ ë°”ì´íŠ¸ ìˆ˜ ê³„ì‚°\n",
    "numel = x.nelement()         # ìš”ì†Œ ê°œìˆ˜ : 1\n",
    "bytes_per = x.element_size() # float32 í•œ ìš”ì†Œë‹¹ 4ë°”ì´íŠ¸\n",
    "\n",
    "# ì‹¤ì œ ë°ì´í„° ë°”ì´íŠ¸ ìˆ˜ ê³„ì‚°\n",
    "tensor_bytes = numel * bytes_per # ì´ 4byte\n",
    "tensor_mb = tensor_bytes / (1024 ** 2)\n",
    "tensor_gb = tensor_bytes / (1024 ** 3)\n",
    "\n",
    "# ì¶œë ¥: B, MB, GB ë‹¨ìœ„ ëª¨ë‘ í‘œì‹œ\n",
    "print(f\"ì‹¤ì œ í…ì„œ ë°ì´í„° í¬ê¸°: {tensor_bytes} B  ({tensor_mb:.6f} MB, {tensor_gb:.9f} GB)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9bd17160-3b04-4d6c-bc4d-ecf877c0837b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-08-01 12:59:22.214347: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-08-01 12:59:22.221740: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1754020762.230221   11067 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1754020762.232925   11067 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1754020762.239910   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754020762.239917   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754020762.239917   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1754020762.239918   11067 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-08-01 12:59:22.242128: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI AVX_VNNI_INT8 AVX_NE_CONVERT FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "Some weights of the model checkpoint at google-bert/bert-large-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[BERT-Large GPU ë¡œë“œ í›„] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 2.63 GB / 15.92 GB\n"
     ]
    }
   ],
   "source": [
    "# 6. BERT-Large ëª¨ë¸ ë¡œë“œ ë° GPUë¡œ ì´ë™\n",
    "from transformers import BertForMaskedLM, BertTokenizerFast\n",
    "\n",
    "# ëª¨ë¸ê³¼ í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "model_name = \"google-bert/bert-large-uncased\"\n",
    "tokenizer = BertTokenizerFast.from_pretrained(model_name)\n",
    "model = BertForMaskedLM.from_pretrained(model_name)\n",
    "\n",
    "# ëª¨ë¸ì„ GPUë¡œ ì´ë™\n",
    "model.to(device)\n",
    "print_gpu_mem(\"BERT-Large GPU ë¡œë“œ í›„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f10e16f-4c3f-41bc-9a00-ff5729feeefd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 13.2833\n",
      "[í•™ìŠµ ìŠ¤í…(batch=4) í›„] GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: 7.77 GB / 15.92 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sallysooo/miniforge3/lib/python3.11/site-packages/torch/nn/modules/module.py:1762: FutureWarning: `encoder_attention_mask` is deprecated and will be removed in version 4.55.0 for `BertSdpaSelfAttention.forward`.\n",
      "  return forward_call(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 7. ê°„ë‹¨ í•™ìŠµ ìŠ¤í… (batch size=4)\n",
    "from torch.optim import AdamW\n",
    "\n",
    "# ë”ë¯¸ ì…ë ¥(batch_size=4, seq_len=8) ìƒì„±\n",
    "batch_size, seq_len = 4, 8\n",
    "input_ids = torch.randint(0, tokenizer.vocab_size, (batch_size, seq_len), device=device)\n",
    "attention_mask = torch.ones_like(input_ids, device=device)\n",
    "labels = input_ids.clone() # ìê¸° ìì‹ ì„ ì˜ˆì¸¡í•˜ë„ë¡\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "\n",
    "model.train()\n",
    "optimizer.zero_grad()\n",
    "outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "loss = outputs.loss\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "print(f'Loss: {loss.item():.4f}')\n",
    "print_gpu_mem(\"í•™ìŠµ ìŠ¤í…(batch=4) í›„\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "889232b4-8d0e-46d6-afb6-3c8bae4eb12e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "\n",
    "def time_operation(operation, *args, n_iters=100):\n",
    "    # GPU sync í›„ ì •í™•í•œ ì‹œê°„ ì¸¡ì • ì‹œì‘\n",
    "    torch.cuda.synchronize()\n",
    "    start = time.time()\n",
    "    for _ in range(n_iters):\n",
    "        operation(*args)\n",
    "    torch.cuda.synchronize()\n",
    "    end = time.time()\n",
    "    \n",
    "    avg_time_ms = (end - start) / n_iters * 1000  # ms ë‹¨ìœ„\n",
    "    return avg_time_ms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ffdfcf7-836c-42c5-bb9b-6a7dec92032e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       Operation  Avg Time (ms)\n",
      "0               GEMM (2048*2048)       0.590971\n",
      "1          LayerNorm (2048*2048)       0.019050\n",
      "2  Element-wise ReLU (2048*2048)       0.013139\n"
     ]
    }
   ],
   "source": [
    "# 1) GEMM (2048*2048)\n",
    "size = 2048\n",
    "A = torch.randn(size, size, device=device)\n",
    "B = torch.randn(size, size, device=device)\n",
    "gemm_time = time_operation(lambda x, y: x.matmul(y), A, B)\n",
    "\n",
    "# 2) LayerNorm (2048*2048)\n",
    "seq_len, hidden = 2048, 2048\n",
    "x = torch.randn(seq_len, hidden, device=device)\n",
    "ln = torch.nn.LayerNorm(hidden).to(device)\n",
    "ln_time = time_operation(lambda inp: ln(inp), x)\n",
    "\n",
    "# 3) Element-wise ReLU (2048*2048)\n",
    "y = torch.randn(size, size, device=device)\n",
    "elt_time = time_operation(lambda inp: inp.relu(), y)\n",
    "\n",
    "# ê²°ê³¼ í”„ë ˆì„\n",
    "df = pd.DataFrame({\n",
    "\t'Operation': ['GEMM (2048*2048)', 'LayerNorm (2048*2048)', 'Element-wise ReLU (2048*2048)'],\n",
    "    'Avg Time (ms)': [gemm_time, ln_time, elt_time]\n",
    "})\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34263eac-4377-40e4-a823-7fb6798ab93f",
   "metadata": {},
   "source": [
    "## 2. Batch Size Choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6016b089-3557-4ea0-b987-ae861b1c6457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "B=   4 | Time:   2.01 ms | âˆ†Mem: +0.03 GB\n",
      "B=   8 | Time:   1.50 ms | âˆ†Mem: +0.06 GB\n",
      "B=  16 | Time:   1.46 ms | âˆ†Mem: +0.06 GB\n",
      "B=  32 | Time:   1.42 ms | âˆ†Mem: +0.06 GB\n",
      "B=  64 | Time:   1.56 ms | âˆ†Mem: +0.06 GB\n",
      "B= 128 | Time:   1.55 ms | âˆ†Mem: +0.06 GB\n",
      "B= 256 | Time:   1.49 ms | âˆ†Mem: +0.06 GB\n",
      "B= 512 | Time:   1.57 ms | âˆ†Mem: +0.06 GB\n",
      "B=1024 | Time:   1.83 ms | âˆ†Mem: +0.06 GB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_11067/1360385232.py:13: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "/tmp/ipykernel_11067/1360385232.py:25: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast(dtype=torch.float16):\n"
     ]
    }
   ],
   "source": [
    "# ë³¸ì¸ ì»´í“¨í„° ì‚¬ì–‘ì—ì„œëŠ” ì–¼ë§ˆì˜ ë°°ì¹˜ê°€ ìµœì ì¸ì§€? (ì‚¬ìš© ëª¨ë¸ ë° ì—°ì‚° ì¢…ë¥˜ ë“±ì— ë”°ë¼ì„œ ë” ë‹¬ë¼ì§ˆ ìˆ˜ ìˆìŒ)\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = torch.nn.Sequential(\n",
    "    torch.nn.Linear(2048, 2048),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(2048, 2048)\n",
    ").to(device)\n",
    "scaler = GradScaler()\n",
    "\n",
    "for B in [4, 8, 16, 32, 64, 128, 256, 512, 1024]:\n",
    "    x = torch.randn(B, 2048, device=device)\n",
    "    y = torch.randn(B, 2048, device=device)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.synchronize()\n",
    "    mem_start = torch.cuda.memory_allocated()\n",
    "\n",
    "    start = time.time()\n",
    "    with autocast(dtype=torch.float16):\n",
    "        out = model(x)\n",
    "        loss = (out - y).abs().mean()\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "    torch.cuda.synchronize()\n",
    "    elapsed_ms = (time.time() - start) * 1000\n",
    "\n",
    "    mem_end = torch.cuda.memory_allocated()\n",
    "    delta_gb = (mem_end - mem_start) / 1024**3\n",
    "\n",
    "    print(f\"B={B:4} | Time: {elapsed_ms:6.2f} ms | âˆ†Mem: {delta_gb:+.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b1f06a5-6dc5-4c70-b37c-18cb77dffcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ” dtype = torch.float32\n",
      "â–¶ 511Ã—511 í–‰ë ¬ê³±: 0.03 ms\n",
      "â–¶ 512Ã—512 í–‰ë ¬ê³±: 0.02 ms\n",
      "â–¶ 513Ã—513 í–‰ë ¬ê³±: 0.04 ms\n",
      "\n",
      "ğŸ” dtype = torch.float16\n",
      "â–¶ 511Ã—511 í–‰ë ¬ê³±: 0.02 ms\n",
      "â–¶ 512Ã—512 í–‰ë ¬ê³±: 0.01 ms\n",
      "â–¶ 513Ã—513 í–‰ë ¬ê³±: 0.02 ms\n"
     ]
    }
   ],
   "source": [
    "# Tiling experiment\n",
    "# í…ŒìŠ¤íŠ¸í•  ë°ì´í„° íƒ€ì…ë“¤\n",
    "dtypes = [torch.float32, torch.float16]\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  í–‰ë ¬ í¬ê¸°ë“¤\n",
    "shapes = [\n",
    "    (511, 511),  # íƒ€ì¼ë³´ë‹¤ ì•½ê°„ ì‘ì€ ê²½ìš°\n",
    "    (512, 512),  # ì´ìƒì ì¸ íƒ€ì¼ í¬ê¸°\n",
    "    (513, 513),  # íƒ€ì¼ë³´ë‹¤ ì•½ê°„ í° ê²½ìš°\n",
    "]\n",
    "\n",
    "for dtype in dtypes:\n",
    "    print(f\"\\nğŸ” dtype = {dtype}\")\n",
    "    for H, W in shapes:\n",
    "        A = torch.randn(H, W, device=device, dtype=dtype)\n",
    "        B = torch.randn(W, H, device=device, dtype=dtype)\n",
    "\n",
    "        # ì›Œë°ì—… (ì´ˆê¸° CUDA ì‹¤í–‰ ì§€ì—° ì œê±°ìš©)\n",
    "        for _ in range(5):\n",
    "            _ = A @ B\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "        # ì†ë„ ì¸¡ì •\n",
    "        start = time.time()\n",
    "        for _ in range(20):\n",
    "            _ = A @ B\n",
    "        torch.cuda.synchronize()\n",
    "        elapsed = (time.time() - start) / 20\n",
    "\n",
    "        print(f\"â–¶ {H}Ã—{W} í–‰ë ¬ê³±: {elapsed * 1000:.2f} ms\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53b9a78b-8e42-4730-924c-e9cc87bde4dc",
   "metadata": {},
   "source": [
    "## 3. Gradient Accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "44d7f58a-476a-4b80-990a-2b597885a0c1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 9.91M/9.91M [00:03<00:00, 2.69MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 28.9k/28.9k [00:00<00:00, 144kB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.65M/1.65M [00:01<00:00, 1.27MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4.54k/4.54k [00:00<00:00, 6.73MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1], Step 40, Loss: 23.0305\n",
      "[Epoch 1], Step 80, Loss: 22.8590\n",
      "[Epoch 1], Step 120, Loss: 22.6783\n",
      "[Epoch 1], Step 160, Loss: 22.5134\n",
      "[Epoch 1], Step 200, Loss: 22.3058\n",
      "[Epoch 1], Step 240, Loss: 22.1221\n",
      "[Epoch 1], Step 280, Loss: 21.9336\n",
      "[Epoch 1], Step 320, Loss: 21.6852\n",
      "[Epoch 1], Step 360, Loss: 21.5077\n",
      "[Epoch 1], Step 400, Loss: 21.3264\n",
      "[Epoch 1], Step 440, Loss: 21.0508\n",
      "[Epoch 1], Step 480, Loss: 20.8227\n",
      "[Epoch 1], Step 520, Loss: 20.6629\n",
      "[Epoch 1], Step 560, Loss: 20.3314\n",
      "[Epoch 1], Step 600, Loss: 20.0644\n",
      "[Epoch 1], Step 640, Loss: 19.7670\n",
      "[Epoch 1], Step 680, Loss: 19.6221\n",
      "[Epoch 1], Step 720, Loss: 19.3917\n",
      "[Epoch 1], Step 760, Loss: 19.0303\n",
      "[Epoch 1], Step 800, Loss: 18.8091\n",
      "[Epoch 1], Step 840, Loss: 18.3280\n",
      "[Epoch 1], Step 880, Loss: 17.9145\n",
      "[Epoch 1], Step 920, Loss: 17.6815\n",
      "[Epoch 1], Step 960, Loss: 17.3458\n",
      "[Epoch 1], Step 1000, Loss: 16.9637\n",
      "[Epoch 1], Step 1040, Loss: 16.5880\n",
      "[Epoch 1], Step 1080, Loss: 16.3032\n",
      "[Epoch 1], Step 1120, Loss: 15.8250\n",
      "[Epoch 1], Step 1160, Loss: 15.5598\n",
      "[Epoch 1], Step 1200, Loss: 15.0634\n",
      "[Epoch 1], Step 1240, Loss: 14.9601\n",
      "[Epoch 1], Step 1280, Loss: 14.7189\n",
      "[Epoch 1], Step 1320, Loss: 14.3601\n",
      "[Epoch 1], Step 1360, Loss: 14.0337\n",
      "[Epoch 1], Step 1400, Loss: 13.4467\n",
      "[Epoch 1], Step 1440, Loss: 13.1825\n",
      "[Epoch 1], Step 1480, Loss: 13.2653\n",
      "[Epoch 1], Step 1520, Loss: 12.6712\n",
      "[Epoch 1], Step 1560, Loss: 12.2089\n",
      "[Epoch 1], Step 1600, Loss: 12.2819\n",
      "[Epoch 1], Step 1640, Loss: 12.2713\n",
      "[Epoch 1], Step 1680, Loss: 11.6150\n",
      "[Epoch 1], Step 1720, Loss: 11.3809\n",
      "[Epoch 1], Step 1760, Loss: 11.0676\n",
      "[Epoch 1], Step 1800, Loss: 11.2058\n",
      "[Epoch 1], Step 1840, Loss: 10.9255\n",
      "[Epoch 2], Step 40, Loss: 10.6119\n",
      "[Epoch 2], Step 80, Loss: 10.1341\n",
      "[Epoch 2], Step 120, Loss: 9.9602\n",
      "[Epoch 2], Step 160, Loss: 9.8754\n",
      "[Epoch 2], Step 200, Loss: 9.8871\n",
      "[Epoch 2], Step 240, Loss: 9.5684\n",
      "[Epoch 2], Step 280, Loss: 9.3752\n",
      "[Epoch 2], Step 320, Loss: 9.2316\n",
      "[Epoch 2], Step 360, Loss: 8.7818\n",
      "[Epoch 2], Step 400, Loss: 8.8345\n",
      "[Epoch 2], Step 440, Loss: 8.7836\n",
      "[Epoch 2], Step 480, Loss: 8.7836\n",
      "[Epoch 2], Step 520, Loss: 8.4388\n",
      "[Epoch 2], Step 560, Loss: 8.3114\n",
      "[Epoch 2], Step 600, Loss: 8.2199\n",
      "[Epoch 2], Step 640, Loss: 8.4316\n",
      "[Epoch 2], Step 680, Loss: 8.1363\n",
      "[Epoch 2], Step 720, Loss: 8.1010\n",
      "[Epoch 2], Step 760, Loss: 7.7610\n",
      "[Epoch 2], Step 800, Loss: 7.9665\n",
      "[Epoch 2], Step 840, Loss: 7.8165\n",
      "[Epoch 2], Step 880, Loss: 7.4888\n",
      "[Epoch 2], Step 920, Loss: 7.3141\n",
      "[Epoch 2], Step 960, Loss: 7.4696\n",
      "[Epoch 2], Step 1000, Loss: 7.3647\n",
      "[Epoch 2], Step 1040, Loss: 7.2859\n",
      "[Epoch 2], Step 1080, Loss: 7.1032\n",
      "[Epoch 2], Step 1120, Loss: 7.2152\n",
      "[Epoch 2], Step 1160, Loss: 7.3305\n",
      "[Epoch 2], Step 1200, Loss: 7.0387\n",
      "[Epoch 2], Step 1240, Loss: 6.7609\n",
      "[Epoch 2], Step 1280, Loss: 6.8497\n",
      "[Epoch 2], Step 1320, Loss: 6.5773\n",
      "[Epoch 2], Step 1360, Loss: 6.9756\n",
      "[Epoch 2], Step 1400, Loss: 6.4442\n",
      "[Epoch 2], Step 1440, Loss: 6.3468\n",
      "[Epoch 2], Step 1480, Loss: 6.1935\n",
      "[Epoch 2], Step 1520, Loss: 6.0806\n",
      "[Epoch 2], Step 1560, Loss: 6.5773\n",
      "[Epoch 2], Step 1600, Loss: 6.3034\n",
      "[Epoch 2], Step 1640, Loss: 6.2931\n",
      "[Epoch 2], Step 1680, Loss: 6.3009\n",
      "[Epoch 2], Step 1720, Loss: 6.4374\n",
      "[Epoch 2], Step 1760, Loss: 6.3416\n",
      "[Epoch 2], Step 1800, Loss: 6.2634\n",
      "[Epoch 2], Step 1840, Loss: 6.0168\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •\n",
    "batch_size = 32              # ì‘ì€ ë°°ì¹˜\n",
    "accumulation_steps = 4       # ëˆ„ì í•  step ìˆ˜\n",
    "lr = 0.01\n",
    "num_epochs = 2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 2. ë°ì´í„°ì…‹ ì¤€ë¹„\n",
    "transform = transforms.ToTensor()\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# 3. ëª¨ë¸ ì •ì˜\n",
    "model = nn.Sequential(\n",
    "    nn.Flatten(),\n",
    "    nn.Linear(28*28, 128),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(128, 10)\n",
    ").to(device)\n",
    "\n",
    "# 4. ì†ì‹¤ í•¨ìˆ˜ ë° ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "# 5. í•™ìŠµ ë£¨í”„ (Gradient Accumulation)\n",
    "model.train()\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for i, (inputs, labels) in enumerate(train_loader):\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # forward + loss\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss = loss / accumulation_steps  # ëˆ„ì ì„ ìœ„í•œ í‰ê· í™”\n",
    "\n",
    "        # backward (ëˆ„ì )\n",
    "        loss.backward()\n",
    "\n",
    "        # ì¼ì • íšŸìˆ˜ë§ˆë‹¤ optimizer step + grad ì´ˆê¸°í™”\n",
    "        if (i + 1) % accumulation_steps == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i + 1) % (accumulation_steps * 10) == 0:\n",
    "            print(f\"[Epoch {epoch+1}], Step {i+1}, Loss: {running_loss:.4f}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a04918-3b89-4a0e-8cb7-c3674d705cda",
   "metadata": {},
   "source": [
    "## 4. Gradient Checkpointing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c2d15989-7861-4135-8b86-4277b0a9abd1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.7616e-02, -3.1428e-02,  6.8262e-03,  3.8644e-02, -6.3441e-03,\n",
      "         -1.9613e-02,  4.1357e-02,  1.9341e-02,  5.2598e-03,  6.3985e-03],\n",
      "        [-1.6576e-02, -5.3709e-02,  4.7012e-03,  4.2796e-02,  3.5075e-02,\n",
      "         -2.6529e-02,  2.8517e-02,  1.2006e-02, -3.5837e-05, -4.5435e-03],\n",
      "        [ 9.6738e-04, -1.7537e-02, -1.0928e-02,  3.5094e-02, -4.9903e-03,\n",
      "         -8.8588e-03,  2.0412e-02,  9.8992e-03,  1.5639e-02, -2.4861e-03],\n",
      "        [-2.0573e-02, -3.0641e-02, -1.2131e-02,  4.4564e-02,  1.8414e-02,\n",
      "         -1.8255e-02,  3.4164e-02,  1.8577e-03,  3.5629e-03,  5.7991e-03],\n",
      "        [-1.6200e-02, -5.1690e-02,  1.1797e-02,  5.1125e-02,  1.7877e-02,\n",
      "         -1.3097e-02,  1.8381e-02,  2.4275e-02,  1.6612e-03, -4.7723e-03],\n",
      "        [-5.3039e-04, -2.5847e-02,  2.3918e-02,  3.3754e-02,  5.1899e-03,\n",
      "         -9.6100e-03,  3.9026e-02,  1.4256e-02,  5.0952e-04, -3.9692e-03],\n",
      "        [-1.2131e-02, -1.7107e-02,  4.9355e-03,  5.8596e-02,  1.5842e-02,\n",
      "         -2.2700e-02,  1.5244e-02,  5.9020e-03, -3.7590e-03,  1.6441e-02],\n",
      "        [-2.3179e-03, -4.4885e-02,  2.6362e-02,  3.5705e-02, -1.7704e-03,\n",
      "         -1.3421e-02,  2.5807e-02, -5.8480e-03, -1.3311e-02, -1.0898e-02],\n",
      "        [-1.0639e-02, -3.5169e-02,  6.8398e-04,  4.1331e-02,  1.6262e-02,\n",
      "         -2.9964e-03,  5.2490e-03,  9.6564e-03, -1.3941e-02, -5.1538e-03],\n",
      "        [-3.8005e-03, -3.9539e-02,  1.1223e-02,  2.6906e-02,  1.2140e-02,\n",
      "         -2.7797e-02,  2.3331e-02,  5.4023e-04, -3.1519e-04,  9.0969e-03],\n",
      "        [-1.2232e-02, -4.3731e-02,  4.4464e-03,  5.5763e-02, -9.3744e-03,\n",
      "         -1.0475e-02,  2.2034e-02,  1.4444e-02, -3.6468e-03, -5.0451e-03],\n",
      "        [ 1.1104e-02, -3.7780e-02,  2.3388e-02,  4.8496e-02,  9.3407e-03,\n",
      "         -2.1039e-02,  2.6993e-02,  1.0775e-03,  5.6857e-03, -6.7896e-03],\n",
      "        [-9.6015e-03, -2.7423e-02,  5.3220e-03,  3.9902e-02,  3.6802e-03,\n",
      "         -1.0856e-02,  2.8703e-02, -8.3622e-04, -7.6974e-03,  5.7542e-04],\n",
      "        [-1.8175e-02, -4.3599e-02,  7.9308e-04,  3.4553e-02,  3.6372e-03,\n",
      "         -3.1136e-02,  3.8265e-02,  2.1064e-02, -1.0095e-02, -6.9517e-03],\n",
      "        [-4.9030e-03, -3.0467e-02,  1.2696e-02,  3.2622e-02,  4.4317e-03,\n",
      "         -1.1520e-02,  2.5786e-02,  1.5583e-03, -8.8683e-03,  3.6830e-03],\n",
      "        [-1.6943e-02, -3.1245e-02,  1.6653e-02,  4.9827e-02,  9.2806e-03,\n",
      "         -1.8329e-02,  2.7521e-02,  1.7156e-02,  7.3846e-03, -1.1943e-02],\n",
      "        [-2.0710e-02, -3.0071e-02,  1.2386e-02,  4.2777e-02,  7.1175e-03,\n",
      "         -2.2052e-02,  8.5191e-03,  1.0244e-02, -3.6861e-03, -8.8057e-03],\n",
      "        [-1.7331e-02, -2.9393e-02, -2.8608e-03,  3.8696e-02,  5.9139e-03,\n",
      "         -2.7232e-02,  1.6828e-02, -4.6842e-03, -1.5204e-02, -1.0062e-02],\n",
      "        [-9.0373e-03, -3.6815e-02,  4.7825e-04,  4.9496e-02,  9.4228e-03,\n",
      "         -2.5500e-02,  2.0563e-02,  2.4567e-02,  7.8603e-03, -1.1906e-02],\n",
      "        [-2.7435e-02, -3.1737e-02,  1.2086e-02,  3.2206e-02,  1.1814e-02,\n",
      "         -3.3808e-02,  9.8887e-03, -8.2141e-03,  2.6903e-03, -1.8056e-02],\n",
      "        [-1.9838e-02, -4.4139e-02, -6.0359e-03,  3.4208e-02, -2.7787e-03,\n",
      "         -1.3976e-02,  3.2824e-02,  5.3565e-03, -6.4125e-03, -1.7383e-02],\n",
      "        [-2.6893e-02, -2.9860e-02, -1.0450e-02,  3.6142e-02, -4.2210e-03,\n",
      "          4.2004e-04,  2.1117e-02, -5.6983e-04, -2.2531e-03,  8.5638e-03],\n",
      "        [-3.1545e-04, -5.7487e-02, -5.6249e-03,  2.3715e-02, -1.0125e-02,\n",
      "         -2.4930e-02,  2.2078e-02,  2.5796e-02, -1.3907e-02, -3.2542e-02],\n",
      "        [-6.5236e-03, -4.0517e-02, -1.6547e-02,  3.8311e-02, -1.2152e-03,\n",
      "         -7.4797e-03,  1.7754e-02,  9.6697e-03, -3.3358e-03,  5.2242e-03],\n",
      "        [-1.7550e-02, -4.1027e-02,  1.2290e-02,  2.6614e-02,  1.4921e-02,\n",
      "         -2.8765e-03,  1.7479e-02,  9.4391e-03,  1.0654e-03, -1.6430e-02],\n",
      "        [-6.4433e-03, -2.9347e-02,  5.0285e-03,  3.4487e-02,  1.4234e-02,\n",
      "         -2.7236e-02,  2.6529e-02, -1.0366e-02, -7.8999e-03,  3.2923e-03],\n",
      "        [-3.4124e-03, -4.3861e-02, -3.1501e-03,  3.5361e-02, -5.6704e-03,\n",
      "         -9.6782e-03,  3.0645e-02,  1.4632e-02,  2.4508e-02, -1.8150e-02],\n",
      "        [-2.5119e-02, -5.0505e-02,  8.7255e-03,  4.5884e-02,  1.0169e-02,\n",
      "         -2.9987e-02,  2.9567e-02, -1.1078e-02, -2.3118e-02, -1.3127e-02],\n",
      "        [-5.6929e-03, -4.3776e-02, -6.8075e-03,  4.1075e-02,  1.2047e-02,\n",
      "         -2.5639e-02,  2.7109e-02,  2.2094e-02, -7.9536e-03,  1.7324e-02],\n",
      "        [-1.7905e-02, -4.0238e-02,  9.0708e-03,  4.6888e-02, -5.2126e-03,\n",
      "         -8.8711e-03,  3.5040e-02,  8.1595e-03,  5.1214e-04, -9.8214e-03],\n",
      "        [-3.3020e-02, -3.4794e-02,  1.1738e-02,  4.5333e-02,  1.4586e-02,\n",
      "         -9.6913e-03,  1.2140e-02,  8.4179e-03, -1.2599e-03, -1.4961e-02],\n",
      "        [-1.2854e-02, -3.8555e-02, -9.0583e-03,  4.3058e-02, -1.0390e-02,\n",
      "         -1.6606e-02,  1.9577e-02,  8.0136e-04,  2.3446e-03,  4.5492e-03],\n",
      "        [ 3.7452e-03, -3.2292e-02,  1.7012e-02,  5.0920e-02,  2.0737e-02,\n",
      "         -2.6386e-02,  3.0444e-02,  2.0558e-02, -8.9942e-03, -8.5440e-03],\n",
      "        [-8.1378e-04, -3.5795e-02,  5.2273e-04,  4.0807e-02,  3.5640e-03,\n",
      "         -1.7721e-02,  3.8172e-02,  1.2146e-02, -5.9907e-03,  4.3804e-03],\n",
      "        [-1.1172e-02, -5.0470e-02,  1.2142e-02,  3.0292e-02,  7.7941e-03,\n",
      "         -1.5085e-02,  2.5021e-02,  2.4344e-03, -5.0067e-03,  6.6600e-04],\n",
      "        [-1.5735e-02, -4.2036e-02, -7.3203e-03,  3.4951e-02, -1.2344e-02,\n",
      "         -2.4653e-02,  3.6478e-02,  9.5518e-03, -1.4927e-02, -7.7627e-03],\n",
      "        [-2.5061e-03, -2.6327e-02,  5.1696e-03,  4.3396e-02,  1.2796e-03,\n",
      "          6.3088e-04,  1.0009e-02,  1.4256e-02,  2.5333e-02, -1.1108e-02],\n",
      "        [-1.6033e-02, -2.9202e-02,  8.4761e-03,  3.2263e-02,  3.1849e-03,\n",
      "         -1.1917e-02,  2.3907e-02,  1.0794e-02, -8.9477e-03, -4.2427e-03],\n",
      "        [ 8.4052e-03, -5.6778e-02,  6.7151e-03,  3.3987e-02,  9.9752e-03,\n",
      "         -1.7247e-02,  2.7354e-02,  2.3763e-03,  7.7211e-03, -2.1166e-02],\n",
      "        [-1.3377e-02, -3.4603e-02,  3.3627e-03,  1.9016e-02, -3.6885e-04,\n",
      "         -1.1118e-02,  3.6261e-02,  1.7723e-02, -7.3170e-03, -9.9798e-04],\n",
      "        [-2.4353e-02, -3.1709e-02, -1.3765e-03,  2.9903e-02,  1.0268e-02,\n",
      "         -2.9177e-02,  2.4618e-02, -5.6468e-05, -2.3101e-02, -5.7912e-03],\n",
      "        [-2.0952e-02, -2.7326e-02,  1.5117e-02,  4.3141e-02,  1.0216e-02,\n",
      "         -1.9674e-02,  1.8570e-02, -5.2182e-03,  6.5174e-03, -4.7797e-03],\n",
      "        [-1.2090e-02, -4.4012e-02,  2.6967e-03,  4.4411e-02,  1.0862e-02,\n",
      "         -2.3770e-02,  2.0148e-02,  1.1667e-02, -5.2732e-03, -6.8767e-03],\n",
      "        [-2.3894e-02, -3.8068e-02,  1.0254e-02,  5.4305e-02, -1.1804e-02,\n",
      "         -1.4340e-02,  3.3792e-02,  8.7996e-03, -6.8141e-03, -7.6301e-03],\n",
      "        [-1.0248e-02, -3.9113e-02,  1.6810e-02,  3.9211e-02,  1.0068e-02,\n",
      "         -5.8659e-03,  1.4435e-02, -7.9668e-03,  1.3434e-02, -6.0932e-03],\n",
      "        [-1.9557e-02, -2.7805e-02,  4.6363e-04,  4.6775e-02,  8.6132e-03,\n",
      "         -1.3958e-02,  2.1014e-02,  6.9003e-03, -1.4121e-02,  9.0437e-04],\n",
      "        [-1.5235e-02, -6.8470e-03,  1.5901e-03,  4.6534e-02, -2.8514e-03,\n",
      "         -1.5324e-03,  2.5945e-02,  8.1543e-03, -9.8737e-03, -5.2560e-03],\n",
      "        [-1.4691e-02, -3.5444e-02,  2.9589e-04,  3.2138e-02,  5.3693e-03,\n",
      "         -2.5067e-02,  1.1407e-02,  1.6632e-02,  7.7760e-03, -6.1849e-03],\n",
      "        [-1.1573e-02, -3.7984e-02, -1.7798e-04,  4.0442e-02,  1.1733e-02,\n",
      "         -1.3463e-02,  1.4173e-02,  2.6836e-03, -1.0517e-02,  4.5877e-03],\n",
      "        [-1.6141e-02, -2.9408e-02,  1.0866e-02,  4.8236e-02,  1.0781e-02,\n",
      "         -1.1109e-02,  1.8712e-02,  1.4089e-02, -3.1054e-03,  3.8409e-03],\n",
      "        [-6.8208e-03, -3.9689e-02,  1.2541e-02,  4.4410e-02,  6.2501e-05,\n",
      "         -9.6774e-03,  3.7307e-02, -4.1606e-03, -1.9793e-03,  2.8538e-03],\n",
      "        [-1.5495e-02, -4.0938e-02,  5.9723e-03,  3.8965e-02,  1.7904e-03,\n",
      "         -2.3624e-02,  1.9916e-02,  4.6189e-03, -9.1278e-03,  9.6748e-03],\n",
      "        [-1.0471e-02, -5.3505e-02, -3.0170e-03,  5.9645e-02,  1.4322e-03,\n",
      "         -1.5734e-02,  1.3923e-02,  2.0365e-02, -1.3117e-02, -1.1064e-02],\n",
      "        [-1.2454e-02, -3.7375e-02, -1.1405e-02,  3.7063e-02,  3.8939e-03,\n",
      "         -1.8590e-02,  1.3661e-02,  8.6877e-03,  8.2183e-03,  2.6843e-03],\n",
      "        [-1.2463e-02, -3.2962e-02,  5.1597e-03,  5.5823e-02, -3.8621e-03,\n",
      "         -6.5245e-03,  2.3848e-02,  3.5166e-02, -1.6691e-02, -2.4696e-04],\n",
      "        [-8.7495e-03, -4.3456e-02, -2.5123e-04,  4.2580e-02,  1.4911e-03,\n",
      "         -2.6320e-02,  4.2281e-02,  2.6967e-03,  2.2592e-03,  1.4167e-03],\n",
      "        [ 4.0432e-03, -2.8470e-02, -4.3356e-03,  2.3731e-02,  2.8476e-03,\n",
      "         -2.8702e-03,  1.0899e-02,  1.4147e-02, -1.6634e-02,  1.1416e-02],\n",
      "        [ 1.8978e-03, -3.1771e-02,  3.6943e-03,  4.2221e-02,  1.9016e-03,\n",
      "         -1.0534e-02,  3.7689e-02,  1.8592e-02, -1.9038e-03,  3.1514e-03],\n",
      "        [-1.9197e-02, -3.3564e-02,  1.7656e-02,  5.5362e-02,  2.5311e-02,\n",
      "         -2.4033e-02,  3.1531e-02, -3.1395e-04, -1.8839e-03,  4.4549e-03],\n",
      "        [-3.2466e-02, -3.1456e-02,  6.4839e-03,  3.1773e-02,  5.9690e-03,\n",
      "         -1.1682e-02,  1.9059e-02,  2.3183e-02, -1.2865e-02, -7.0795e-03],\n",
      "        [-2.4759e-02, -4.0718e-02,  2.7331e-03,  4.0274e-02,  1.0598e-02,\n",
      "         -1.9789e-02,  2.4178e-02,  1.9009e-02, -2.3519e-02, -1.1667e-02],\n",
      "        [-1.5732e-02, -3.7768e-02,  2.2015e-03,  4.6788e-02, -8.9801e-03,\n",
      "         -7.1381e-03,  2.0617e-02,  1.1092e-02, -2.8157e-02, -1.2468e-02],\n",
      "        [-8.4339e-03, -3.0727e-02,  4.6438e-03,  3.1174e-02,  6.3490e-03,\n",
      "         -2.4129e-02,  3.2648e-02,  9.0020e-03, -5.6178e-03,  8.6927e-03],\n",
      "        [-2.5939e-02, -1.8101e-02,  3.7063e-03,  4.3243e-02,  2.2336e-02,\n",
      "         -1.5387e-02,  1.5589e-02,  1.9052e-02, -1.7311e-02,  3.8516e-03]],\n",
      "       device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.utils.checkpoint as checkpoint\n",
    "\n",
    "class MyBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.seq = nn.Sequential(\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 1024),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return checkpoint.checkpoint(self.seq, x)\n",
    "\n",
    "class BigModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = MyBlock()\n",
    "        self.block2 = MyBlock()\n",
    "        self.fc = nn.Linear(1024, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        return self.fc(x)\n",
    "\n",
    "model = BigModel().cuda()\n",
    "x = torch.randn(64, 1024, device='cuda')  # batch size = 64\n",
    "output = model(x)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e13c5866-1adb-475f-a098-98bae04aa373",
   "metadata": {},
   "source": [
    "## 5. Mixed Precision Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6b88c3-9643-4327-8ad3-4aec2250c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4,                # ì‹¤ ë°°ì¹˜\n",
    "    gradient_accumulation_steps=8,                # ëˆ„ì  ë°°ì¹˜ â†’ ì´ 4x8=32\n",
    "    fp16=True,                                    # Mixed Precision í™œì„±í™” (FP16)\n",
    "    # bf16=True,                                  # BF16 ì‚¬ìš© ì‹œ ì£¼ì„ í•´ì œ\n",
    "    learning_rate=5e-5,\n",
    "    logging_steps=50,\n",
    "    save_steps=500,\n",
    "    evaluation_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    report_to=\"wandb\",                            # WandB ë¡œê¹…\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

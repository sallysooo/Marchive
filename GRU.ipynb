{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dYrNw4JOe08X",
   "metadata": {
    "id": "dYrNw4JOe08X"
   },
   "source": [
    "### GRU Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ace190",
   "metadata": {},
   "source": [
    "- GRU is a variant of RNNs with a simpler structure than LSTM. Like LSTM, they address long-term dependencies, but require less computation and are simpler to implement.\n",
    "\n",
    "| Item | LSTM | GRU |\n",
    "| -------- | ------------------------- | --------------------- |\n",
    "| Number of Gates | 3: Forget, Input, Output | 2: Update, Reset |\n",
    "| Cell State `c` | Yes (`c`) | No (only uses hidden state) |\n",
    "| Output | `tanh(c) * output_gate` | Uses directly computed `hidden` |\n",
    "| Number of Parameters | Relatively More | Fewer |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c54668a4",
   "metadata": {
    "id": "c54668a4"
   },
   "outputs": [],
   "source": [
    "# GRUCell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1e52852",
   "metadata": {
    "id": "d1e52852"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dataset\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Parameter\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import math\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "cuda = True if torch.cuda.is_available() else False\n",
    "\n",
    "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
    "\n",
    "torch.manual_seed(125)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6a357411",
   "metadata": {
    "id": "6a357411"
   },
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (1.0,))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e58e536d",
   "metadata": {
    "id": "e58e536d"
   },
   "outputs": [],
   "source": [
    "from torchvision.datasets import MNIST\n",
    "download_root = 'MNIST_DATASET/'\n",
    "\n",
    "train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28f097a8",
   "metadata": {
    "id": "28f097a8"
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "valid_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9a258e",
   "metadata": {
    "id": "8e9a258e"
   },
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "n_iters = 6000\n",
    "num_epochs = n_iters / (len(train_dataset) / batch_size)\n",
    "num_epochs = int(num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8190f8e5",
   "metadata": {
    "id": "8190f8e5"
   },
   "outputs": [],
   "source": [
    "class GRUCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True):\n",
    "        super(GRUCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.bias = bias\n",
    "        # Since GRU computes three vectors at once, each linear transformation specify output size as 3*hidden_size\n",
    "        self.x2h = nn.Linear(input_size, 3 * hidden_size, bias=bias)\n",
    "        self.h2h = nn.Linear(hidden_size, 3 * hidden_size, bias=bias)\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        std = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for w in self.parameters():\n",
    "            w.data.uniform_(-std, std)\n",
    "\n",
    "    def forward(self, x, hidden):\n",
    "        x = x.view(-1, x.size(1))   # (batch_size, input_dim)\n",
    "\n",
    "        gate_x = self.x2h(x)        # (batch_size, 3*hidden_size)\n",
    "        gate_h = self.h2h(hidden)\n",
    "\n",
    "        gate_x = gate_x.squeeze()\n",
    "        gate_h = gate_h.squeeze()\n",
    "\n",
    "        # Divide the linear transformation result into three parts for reset, update, and new gate\n",
    "        i_r, i_i, i_n =  gate_x.chunk(3, 1)\n",
    "        h_r, h_i, h_n =  gate_h.chunk(3, 1)\n",
    "\n",
    "        resetgate = torch.sigmoid(i_r + h_r)\n",
    "        inputgate = torch.sigmoid(i_i + h_i)\n",
    "        newgate = torch.tanh(i_n + resetgate * h_n)\n",
    "        '''\n",
    "        Calculate the new gate (candidate hidden state)\n",
    "        : Multiplying the previous hidden state by the resetgate controls how much past information is reflected.\n",
    "        '''\n",
    "        hy = newgate + inputgate * (hidden - newgate)\n",
    "        return hy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3630ad8a",
   "metadata": {},
   "source": [
    "| Variables | Description |\n",
    "| ------------ | -------------------------------- |\n",
    "| `i_r`, `h_r` | Input and hidden transformations for the reset gate |\n",
    "| `i_i`, `h_i` | Input and hidden transformations for the update gate |\n",
    "| `i_n`, `h_n` | Input and hidden transformations for the new gate |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9841480f",
   "metadata": {
    "id": "9841480f"
   },
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, layer_dim, output_dim, bias=True):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.layer_dim = layer_dim\n",
    "        self.gru_cell = GRUCell(input_dim, hidden_dim, bias)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x): # x.shape : (batch_size, seq_len=28, input_dim=28)\n",
    "        if torch.cuda.is_available():\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim).cuda())\n",
    "        else:\n",
    "            h0 = Variable(torch.zeros(self.layer_dim, x.size(0), self.hidden_dim))\n",
    "\n",
    "        outs = []\n",
    "        hn = h0[0,:,:]\n",
    "\n",
    "        # x[:,seq,:] : input at the seqth time point with shape (batch_size, input_dim)\n",
    "        # Calcultate the current hidden state based on the previous hidden state hn\n",
    "        # Update hn and store its value in outs[].\n",
    "        for seq in range(x.size(1)):\n",
    "            hn = self.gru_cell(x[:,seq,:], hn)\n",
    "            outs.append(hn)\n",
    "\n",
    "        out = outs[-1].squeeze()\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4328942",
   "metadata": {
    "id": "a4328942"
   },
   "outputs": [],
   "source": [
    "input_dim = 28\n",
    "hidden_dim = 128\n",
    "layer_dim = 1\n",
    "output_dim = 10\n",
    "\n",
    "model = GRUModel(input_dim, hidden_dim, layer_dim, output_dim)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.1\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "880e4755",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "880e4755",
    "outputId": "1435aabf-b8df-46d4-8c1f-f88187a93b46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 500. Loss: 1.661692500114441. Accuracy: 43.59000015258789\n",
      "Iteration: 1000. Loss: 0.8945668935775757. Accuracy: 76.19999694824219\n",
      "Iteration: 1500. Loss: 0.29147765040397644. Accuracy: 89.7300033569336\n",
      "Iteration: 2000. Loss: 0.23627924919128418. Accuracy: 93.51000213623047\n",
      "Iteration: 2500. Loss: 0.03288724273443222. Accuracy: 95.05000305175781\n",
      "Iteration: 3000. Loss: 0.030374977737665176. Accuracy: 95.81999969482422\n",
      "Iteration: 3500. Loss: 0.16210564970970154. Accuracy: 96.33999633789062\n",
      "Iteration: 4000. Loss: 0.193087637424469. Accuracy: 96.19000244140625\n",
      "Iteration: 4500. Loss: 0.05172000452876091. Accuracy: 97.0\n",
      "Iteration: 5000. Loss: 0.13900183141231537. Accuracy: 97.26000213623047\n",
      "Iteration: 5500. Loss: 0.0809028148651123. Accuracy: 97.62000274658203\n",
      "Iteration: 6000. Loss: 0.10488365590572357. Accuracy: 97.69000244140625\n",
      "Iteration: 6500. Loss: 0.07984019070863724. Accuracy: 97.80000305175781\n",
      "Iteration: 7000. Loss: 0.1025039404630661. Accuracy: 97.55999755859375\n",
      "Iteration: 7500. Loss: 0.0647798627614975. Accuracy: 97.86000061035156\n",
      "Iteration: 8000. Loss: 0.10547608882188797. Accuracy: 97.80000305175781\n",
      "Iteration: 8500. Loss: 0.042811598628759384. Accuracy: 98.0199966430664\n",
      "Iteration: 9000. Loss: 0.041988663375377655. Accuracy: 98.22000122070312\n"
     ]
    }
   ],
   "source": [
    "seq_dim = 28\n",
    "loss_list = []\n",
    "iter = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "            labels = Variable(labels.cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim))\n",
    "            labels = Variable(labels)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            loss.cuda()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_list.append(loss.item())\n",
    "        iter += 1\n",
    "\n",
    "        if iter % 500 == 0:\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for images, labels in valid_loader:\n",
    "                if torch.cuda.is_available():\n",
    "                    images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "                else:\n",
    "                    images = Variable(images.view(-1 , seq_dim, input_dim))\n",
    "\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "\n",
    "                if torch.cuda.is_available():\n",
    "                    correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "                else:\n",
    "                    correct += (predicted == labels).sum()\n",
    "\n",
    "            accuracy = 100 * correct / total\n",
    "            print('Iteration: {}. Loss: {}. Accuracy: {}'.format(iter, loss.item(), accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909efc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_iter):\n",
    "    corrects, total, total_loss = 0, 0, 0\n",
    "    model.eval() # MUST!! for the evaluation mode\n",
    "    for images, labels in val_iter:\n",
    "        if torch.cuda.is_available():\n",
    "            images = Variable(images.view(-1, seq_dim, input_dim).cuda())\n",
    "        else:\n",
    "            images = Variable(images.view(-1 , seq_dim, input_dim)).to(device)\n",
    "        labels = labels.cuda()\n",
    "        logit = model(images).cuda()\n",
    "        loss = F.cross_entropy(logit, labels, reduction = \"sum\")\n",
    "        _, predicted = torch.max(logit.data, 1) # The index with the highest predicted probability is considered as the class prediction\n",
    "        total += labels.size(0)\n",
    "        total_loss += loss.item()\n",
    "        corrects += (predicted == labels).sum()\n",
    "\n",
    "    avg_loss = total_loss / len(val_iter.dataset)\n",
    "    avg_accuracy = corrects / total\n",
    "    return avg_loss, avg_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c6080b17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c6080b17",
    "outputId": "f1aaabb8-9006-48e2-9f6e-d19a548b4026"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss:  0.07 | Test Accuracy:  0.98\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = evaluate(model,test_loader)\n",
    "print(\"Test Loss: %5.2f | Test Accuracy: %5.2f\" % (test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
